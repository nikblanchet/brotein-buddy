# Modern CI/CD: From Pull Request to Production with GitHub Actions and Vercel

## Introduction

Continuous Integration and Continuous Deployment (CI/CD) is one of those things that sounds enterprise-y and complicated, but it's actually pretty straightforward once you get the hang of it. At its core, CI/CD is about **automation** and **confidence** - automating the boring stuff (running tests, checking code quality) and giving you confidence that what you're deploying actually works.

This document walks through BroteinBuddy's CI/CD setup using GitHub Actions for testing and Vercel for deployment. We'll cover what these tools do, why they matter, and how they work together to create a smooth development workflow.

## What is CI/CD?

Let's break down the acronym:

### Continuous Integration (CI)

**What it is:** Automatically running tests and checks every time code is pushed to the repository.

**Why it matters:**
- Catches bugs early, before they reach production
- Ensures code meets quality standards (linting, formatting, types)
- Prevents "works on my machine" problems
- Makes code review easier (reviewers know tests pass)

**Real-world analogy:** It's like spell-check and grammar-check for code. Sure, you could manually proofread everything, but why not let the computer catch obvious mistakes?

### Continuous Deployment (CD)

**What it is:** Automatically deploying code to production (or preview environments) when tests pass.

**Why it matters:**
- No manual deployment steps to forget
- Consistent deployment process every time
- Fast feedback loop (see changes live quickly)
- Preview deployments let you test before merging

**Real-world analogy:** It's like having a robot assistant who publishes your blog post the moment you finish writing and proofreading it. No manual upload, no FTP, no forgetting to hit "publish."

### The Developer Experience Benefits

Here's what CI/CD actually does for you day-to-day:

1. **Peace of mind** - If CI passes, you're probably good
2. **Faster reviews** - Reviewers can focus on logic, not style
3. **Less context switching** - No manual deployment dance
4. **Confidence** - Preview deployments let you test before merging
5. **Documentation** - CI logs show exactly what passed/failed

## What is GitHub Actions?

GitHub Actions is GitHub's built-in CI/CD platform. It runs automated workflows triggered by events in your repository (like pushing code or opening a pull request).

### Key Concepts

#### Workflows

A **workflow** is a YAML file that defines what to run and when. In BroteinBuddy, we have one workflow: `.github/workflows/ci.yml`

Think of it like a recipe - it lists out all the steps to execute in order.

#### Jobs

A **job** is a set of steps that run on the same machine. Our CI workflow has one job called `lint-and-test`.

Jobs can run in parallel (useful for testing on multiple platforms) or sequentially (when one depends on another). We only need one job since we're just building a web app.

#### Steps

A **step** is a single action or command. Examples:
- Checkout code
- Install dependencies
- Run tests
- Upload artifacts

Steps run sequentially within a job. If any step fails, the job fails.

#### Triggers

Workflows run in response to events. Our CI workflow triggers on:
- `push` to `main` branch
- `pull_request` targeting `main` branch

This means every PR runs CI, and merging to main re-runs CI.

### How to Read a GitHub Actions YAML File

YAML is whitespace-sensitive (like Python). Indentation matters!

Basic structure:
```yaml
name: Workflow Name
on: [trigger events]
jobs:
  job-name:
    runs-on: ubuntu-latest
    steps:
      - name: Step description
        run: command to execute
```

Comments start with `#`:
```yaml
# This is a comment
run: npm test  # This runs tests
```

## Our CI Workflow: A Deep Dive

Let's walk through `.github/workflows/ci.yml` step by step.

### The Header

```yaml
name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
```

**What it does:**
- Names the workflow "CI" (shows up in GitHub UI)
- Triggers on pushes to `main`
- Triggers on pull requests targeting `main`

**Why these triggers?**
- **Push to main**: Ensures main stays green (all tests pass)
- **Pull requests**: Validates changes before they merge

**What we didn't do:** Trigger on every push to every branch. That would waste CI minutes. We only care about code heading to main.

### The Job Definition

```yaml
jobs:
  lint-and-test:
    runs-on: ubuntu-latest
```

**What it does:**
- Creates a job named `lint-and-test`
- Runs on a fresh Ubuntu machine (GitHub provides this)

**Why Ubuntu?**
- It's free (GitHub gives more minutes for Linux than Windows/macOS)
- Matches production environment (Vercel runs on Linux)
- Fast startup time

**Alternative:** We could run on `macos-latest` or `windows-latest` if we needed to test platform-specific code, but we're building a web app - the platform doesn't matter.

### Step 1: Checkout Code

```yaml
- name: Checkout code
  uses: actions/checkout@v4
```

**What it does:** Downloads your repository code to the CI machine.

**Why it's needed:** By default, the CI machine is empty. This step clones your repo so subsequent steps can access your code.

**The `uses` keyword:** This runs a pre-built action from GitHub's marketplace. `actions/checkout` is official and maintained by GitHub. The `@v4` pins the version (so updates don't break your workflow).

### Step 2: Setup Node.js

```yaml
- name: Setup Node.js
  uses: actions/setup-node@v4
  with:
    node-version: '20'
    cache: 'npm'
```

**What it does:**
- Installs Node.js version 20
- Caches npm dependencies for faster builds

**Why Node 20?**
- It's the current LTS (Long-Term Support) version
- Matches what we use in development
- Vercel supports it

**The cache trick:** The `cache: 'npm'` line makes subsequent runs faster by caching `node_modules`. First run: slow (downloads everything). Second run: fast (reuses cache). This can save 30-60 seconds per run.

### Step 3: Install Dependencies

```yaml
- name: Install dependencies
  run: npm ci
```

**What it does:** Installs all dependencies from `package-lock.json`.

**Why `npm ci` instead of `npm install`?**
- `npm ci` is designed for CI environments
- It's faster (skips some checks)
- It's deterministic (always produces identical results)
- It deletes `node_modules` first (ensures clean install)
- It fails if `package-lock.json` is out of sync with `package.json`

**Real-world trade-off:** `npm ci` is stricter than `npm install`. This is good in CI (we want reproducibility) but annoying in local dev (where you want flexibility). That's why we use `npm install` locally but `npm ci` in CI.

### Step 4: Run Linter

```yaml
- name: Run linter
  run: npm run lint
```

**What it does:** Runs ESLint to check for code quality issues.

**What gets checked:**
- TypeScript errors
- Svelte component issues
- Code style violations
- Potential bugs (unused variables, etc.)

**Why run this in CI?**
- Catches mistakes before code review
- Enforces consistent code style
- Pre-commit hooks can fail (or be bypassed with `--no-verify`)

**If this fails:** Fix the linting errors locally with `npm run lint`, then push again.

### Step 5: Check Code Formatting

```yaml
- name: Check code formatting
  run: npm run format:check
```

**What it does:** Runs Prettier to verify all code is formatted consistently.

**Why separate from linting?**
- Linting finds bugs and bad practices
- Formatting is purely aesthetic (spaces, line breaks, etc.)
- Prettier and ESLint handle different concerns

**Why not auto-fix in CI?**
We could have CI auto-format and commit, but that's complex and can cause confusion. Better to fail CI and ask the developer to format locally. Developers should run `npm run format` before committing (ideally in a pre-commit hook).

### Step 6: Run Type Check

```yaml
- name: Run type check
  run: npm run check
```

**What it does:** Runs Svelte's type checker and TypeScript compiler.

**What gets checked:**
- TypeScript type errors
- Svelte component type issues
- Missing type definitions
- Invalid prop types

**Why this matters:** TypeScript catches an entire class of bugs at build time. Type errors in production would be runtime errors (crashes). Much better to catch them here.

**Real-world compromise:** Strict type checking is annoying when prototyping. We could use `// @ts-ignore` to bypass checks temporarily, but CI will still catch it. This is intentional - it forces us to fix types before merging.

### Step 7: Run Tests with Coverage

```yaml
- name: Run tests with coverage
  run: npm run test:coverage
  # Vitest is configured with 90% coverage thresholds and will fail if not met
```

**What it does:**
- Runs all unit and integration tests
- Measures code coverage
- Fails if coverage is below 90%

**Why 90% coverage?**
- High enough to catch most bugs
- Low enough to be achievable without busywork
- Industry standard for well-tested code

**Coverage threshold enforcement:** This is configured in `vitest.config.ts`:
```typescript
coverage: {
  lines: 90,
  functions: 90,
  branches: 90,
  statements: 90
}
```

If coverage drops below 90% in any category, CI fails. This prevents untested code from sneaking in.

**The comment:** Comments in workflows are helpful! They remind future you (or other developers) why something is configured a certain way.

**If this fails:** Two possibilities:
1. Tests are failing - fix the bugs
2. Coverage is too low - add more tests

Run `npm run test:coverage` locally to see what's not covered.

### Step 8: Build Project

```yaml
- name: Build project
  run: npm run build
```

**What it does:** Runs Vite to build the production bundle.

**Why this matters:**
- Ensures the code actually compiles
- Catches build-time errors (missing imports, etc.)
- Verifies production config works

**Why run this after tests?**
Tests are faster than builds. Fail fast - if tests fail, don't waste time building.

**Real-world note:** Some CI workflows build first, then test the built code. We test source code, then build. Both approaches work. Testing source code is faster (no build step first) and gives better error messages.

### Step 9: Upload Coverage Reports

```yaml
- name: Upload coverage reports
  uses: codecov/codecov-action@v4
  if: always()
  with:
    token: ${{ secrets.CODECOV_TOKEN }}
    fail_ci_if_error: false
```

**What it does:** Uploads coverage data to Codecov for visualization and tracking.

**The `if: always()` trick:** This step runs even if previous steps failed. Why? We want coverage reports even for failing PRs.

**Secrets:** The `${{ secrets.CODECOV_TOKEN }}` is a GitHub secret. It's stored securely in repository settings, not in code. This is how you handle API keys in CI.

**`fail_ci_if_error: false`:** If Codecov upload fails (maybe their API is down), don't fail the entire CI run. Coverage upload is nice-to-have, not critical.

**Optional step:** This is optional. BroteinBuddy works fine without Codecov - it just provides pretty coverage graphs and PR comments.

## Quality Gates: What CI Enforces

Our CI workflow acts as a **quality gate** - code can't merge unless it passes these checks:

1. ✅ **Linting** - No ESLint errors
2. ✅ **Formatting** - All code is Prettier-formatted
3. ✅ **Types** - No TypeScript errors
4. ✅ **Tests** - All tests pass
5. ✅ **Coverage** - At least 90% coverage
6. ✅ **Build** - Production build succeeds

This creates a contract: "If it's on main, it passed all these checks."

**Why this matters:** Bugs still slip through (tests can't catch everything), but you've eliminated entire categories of issues:
- No syntax errors
- No type mismatches
- No untested code paths
- No unformatted code

## What is Vercel?

Vercel is a hosting platform designed for frontend frameworks. It's like Heroku for static sites and serverless functions.

### Why We Chose Vercel

There are many deployment options: Netlify, GitHub Pages, AWS, Firebase, etc. We chose Vercel because:

1. **Framework detection** - It auto-detects Vite and configures build settings
2. **Preview deployments** - Every PR gets a unique URL
3. **Zero configuration** - Works out of the box with sane defaults
4. **Performance** - Edge network for fast global delivery
5. **Free tier** - More than enough for personal projects
6. **GitHub integration** - Deploys on every push automatically

**What we sacrificed:** Full control. Vercel is opinionated - it wants you to do things their way. For complex projects with custom server logic, you might need a different host. But for a static Svelte app? Vercel is perfect.

### Preview Deployments vs Production

Vercel creates two types of deployments:

#### Preview Deployments
- **Trigger:** Every push to a PR
- **URL:** Unique per PR (`project-name-git-branch-user.vercel.app`)
- **Purpose:** Test changes before merging
- **Lifecycle:** Deleted when PR is closed

Preview deployments are magical for collaboration:
- Share a link with non-technical stakeholders
- Test on real phones (not just localhost)
- Verify changes without merging
- Each commit updates the preview (no manual re-deploy)

#### Production Deployment
- **Trigger:** Every push to `main` branch
- **URL:** Stable production URL (`project-name.vercel.app` or custom domain)
- **Purpose:** The live app users access
- **Lifecycle:** Permanent (until you deploy again)

**The workflow:**
1. Open PR → Vercel creates preview
2. Make changes → Preview updates automatically
3. Review and test preview
4. Merge PR → Vercel deploys to production

### How Vercel Integrates with GitHub

When you connect Vercel to a GitHub repository:

1. **Vercel bot** gets access to your repo
2. **Webhooks** notify Vercel of pushes and PRs
3. **Checks** appear on PRs showing deployment status
4. **Comments** post preview URLs on PRs

No configuration needed - Vercel handles this automatically.

## The vercel.json Configuration

The `vercel.json` file customizes how Vercel builds and serves your app.

### Build Configuration

```json
{
  "buildCommand": "npm run build",
  "outputDirectory": "dist",
  "devCommand": "npm run dev",
  "installCommand": "npm install",
  "framework": "vite"
}
```

**What it does:**
- `buildCommand` - Command to build production assets
- `outputDirectory` - Where build output lives (Vite uses `dist`)
- `devCommand` - Command for local dev (Vercel CLI can run this)
- `installCommand` - How to install dependencies
- `framework` - Tells Vercel this is a Vite project (enables optimizations)

**Why specify these?** Vercel auto-detects most of this, but explicit configuration prevents surprises if defaults change.

### Rewrites for SPA Routing

```json
{
  "rewrites": [
    {
      "source": "/(.*)",
      "destination": "/index.html"
    }
  ]
}
```

**What it does:** Routes all requests to `index.html`.

**Why this matters:** BroteinBuddy is a Single-Page Application (SPA). All routing happens client-side in JavaScript. Without this rewrite rule:
- `example.com/` works (serves index.html)
- `example.com/inventory` returns 404 (no inventory.html file)

With the rewrite:
- All URLs serve `index.html`
- JavaScript router takes over and renders the right page

**Real-world gotcha:** If you refresh the browser on `/inventory`, the browser requests `/inventory` from the server. Without SPA rewrites, this 404s. With rewrites, it serves `index.html`, which boots the app and routes to the inventory page.

### Security Headers

```json
{
  "headers": [
    {
      "source": "/(.*)",
      "headers": [
        {
          "key": "X-Content-Type-Options",
          "value": "nosniff"
        },
        {
          "key": "X-Frame-Options",
          "value": "DENY"
        },
        {
          "key": "X-XSS-Protection",
          "value": "1; mode=block"
        }
      ]
    }
  ]
}
```

**What these do:**

1. **X-Content-Type-Options: nosniff**
   - Prevents browsers from MIME-sniffing
   - Stops browser from executing CSS as JavaScript (real security issue)

2. **X-Frame-Options: DENY**
   - Prevents embedding your site in `<iframe>`
   - Blocks clickjacking attacks

3. **X-XSS-Protection: 1; mode=block**
   - Enables browser's built-in XSS filter
   - Blocks page if XSS detected (rather than sanitizing)

**Why add these?** Defense in depth. These headers mitigate entire classes of attacks. They don't replace good code security, but they add extra layers of protection.

**Trade-off:** `X-Frame-Options: DENY` means you can't embed your app in an iframe anywhere. If you wanted to embed BroteinBuddy in another site, you'd need to change this to `SAMEORIGIN` or remove it entirely.

### Service Worker Caching

```json
{
  "source": "/service-worker.js",
  "headers": [
    {
      "key": "Cache-Control",
      "value": "public, max-age=0, must-revalidate"
    }
  ]
}
```

**What it does:** Tells browsers not to cache the service worker file.

**Why this matters:** Service workers control caching for your entire app. If the browser caches the service worker itself, updates won't be picked up. This header ensures:
- Browser checks for new service worker on every page load
- Service worker updates propagate quickly
- No stale service workers serving old cached content

**The values explained:**
- `public` - Can be cached by browsers and CDNs
- `max-age=0` - Expires immediately (always revalidate)
- `must-revalidate` - Must check with server before using cached version

**Real-world problem:** Without this, you deploy a new version, but users keep seeing the old version because their browser cached the service worker. This is a common PWA gotcha.

## The Complete CI/CD Flow

Let's walk through a typical development workflow end-to-end:

### 1. Developer Creates a Pull Request

```bash
git checkout -b feature/new-feature
# Make changes
git commit -m "Add new feature"
git push origin feature/new-feature
# Open PR on GitHub
```

**What happens:**
- PR appears on GitHub
- GitHub notifies CI and Vercel via webhooks

### 2. CI Runs Automatically

Within seconds:
- GitHub Actions starts the CI workflow
- Status appears on PR: "CI / lint-and-test — In progress"
- Yellow dot next to commit hash

Meanwhile:
- Lint checks code style
- Type checker validates types
- Tests run and measure coverage
- Build creates production bundle

**Possible outcomes:**
- ✅ All pass - Green checkmark, CI succeeds
- ❌ Something fails - Red X, CI fails

### 3. Vercel Creates Preview Deployment

At the same time as CI:
- Vercel starts building the PR
- Status appears: "Vercel — Building"
- Preview URL is generated

A few minutes later:
- Build completes
- Preview deployment is live
- Vercel bot comments on PR with preview URL
- Status updates: "Vercel — Ready"

### 4. Code Review Happens

Reviewer can:
- Read the code changes
- See that CI passed (or failed)
- Click preview URL to test changes
- Leave comments and request changes

**Why preview deployments matter:** Instead of saying "does this button work?", reviewer clicks the link and tries it. Non-technical stakeholders can test too - no need to pull code and run locally.

### 5. Developer Makes Updates

If changes requested:
```bash
# Make fixes
git commit -m "Address review feedback"
git push
```

**What happens:**
- CI re-runs automatically
- Preview deployment updates
- Reviewers see new changes reflected in preview

No manual re-deploy needed. This is the magic of CI/CD.

### 6. PR is Approved and Merged

Reviewer approves:
- "Looks good to me! ✅"
- Merge button turns green

Developer merges:
- Squash and merge to main
- PR closes
- Branch gets deleted (optional)

### 7. Production Deployment

Within seconds of merge:
- CI runs on main (final check)
- Vercel starts production deployment
- Status appears on commit in main branch

A few minutes later:
- Production deployment completes
- New version is live at production URL
- Preview deployment gets deleted (no longer needed)

### 8. Status Badges Reflect Current State

On the README:
- ![CI](badge) - Shows latest CI status
- ![codecov](badge) - Shows current coverage percentage

These update automatically. Green badges = healthy project.

## Best Practices

### 1. Never Bypass CI

It's tempting to push directly to main or use `git push --no-verify` to skip hooks. Don't.

**Why:**
- CI catches mistakes you miss
- Broken main blocks other developers
- No preview deployment = no testing before production

**If CI is slow:** Optimize CI (better caching, parallel jobs, faster tests), don't bypass it.

### 2. Fix Broken Tests Immediately

If main is red (CI failing):
- Stop feature work
- Fix main ASAP
- Don't open more PRs until main is green

**Why:** Broken main is a snowball:
- New PRs are based on broken code
- Can't tell if new failures are from new code or existing issues
- Team loses confidence in CI

**Exception:** If a flaky test is causing issues, disable it with `test.skip()` and create an issue to fix it properly.

### 3. Use Preview Deployments for Testing

Before merging:
- Click the preview URL
- Test the actual feature
- Try it on your phone
- Share with stakeholders if relevant

**Why:** CI tests logic, but preview deployments test the actual user experience. You might have passing tests but a broken UI.

### 4. Monitor Status Badges

Glance at README badges periodically:
- Green CI = healthy build
- Red CI = something broke
- Coverage percentage = quality trend

**Why:** Status badges give you a pulse check without opening GitHub Actions logs.

### 5. Keep Main Branch Stable

Main should always be:
- ✅ All tests passing
- ✅ All CI checks green
- ✅ Deployable to production

**How:**
- Require CI to pass before merge (GitHub setting)
- Use pull requests (no direct pushes)
- Review changes before merging

**Why:** Main is your source of truth. If main is broken, everything downstream breaks.

## Common Pitfalls and Solutions

### Problem: Flaky Tests

**Symptom:** Tests pass sometimes, fail other times, with no code changes.

**Common causes:**
- Race conditions in async code
- Tests depend on execution order
- Timing issues (animations, network requests)
- Random data without fixed seeds

**Solutions:**
1. Use `await` properly in async tests
2. Make tests independent (no shared state)
3. Use `vi.useFakeTimers()` for time-dependent code
4. Use fixed seeds for random data
5. Disable animation in tests

**Short-term fix:** If you can't fix immediately:
```typescript
test.skip('flaky test', () => {
  // Skip for now, fix later
});
```

Create an issue to track it. Flaky tests erode confidence in CI.

### Problem: Coverage Threshold Failures

**Symptom:** Tests pass, but CI fails with "Coverage below threshold."

**Why:** New code added without tests, or old coverage deleted.

**Solutions:**
1. Run `npm run test:coverage` locally
2. Look at coverage report (shows uncovered lines)
3. Add tests for uncovered code
4. If testing is truly impossible (rare), adjust thresholds

**Common uncovered code:**
- Error handlers that never trigger in tests
- Edge cases you didn't think of
- Defensive checks that seem obvious

Don't just chase coverage numbers. Write meaningful tests.

### Problem: Build Succeeds Locally but Fails in CI

**Symptom:** `npm run build` works on your machine, CI build fails.

**Common causes:**
1. **Dependency issues** - Missing package in `package.json`
2. **Environment differences** - Node version mismatch
3. **Case sensitivity** - macOS is case-insensitive, Linux isn't
4. **Environment variables** - Present locally but not in CI
5. **Cached issues** - Local cache hiding problems

**Solutions:**
1. Run `npm ci` locally (clean install like CI)
2. Check Node version matches `.github/workflows/ci.yml`
3. Verify file imports match actual file casing
4. Add environment variables to GitHub secrets if needed
5. Delete `node_modules` and reinstall

**Debug tip:** GitHub Actions logs show exact error. Look at the full output, not just the summary.

### Problem: Vercel Preview Deployment Works but Production Fails

**Symptom:** Preview looks good, but production has errors.

**Why:** Environment differences between preview and production.

**Common causes:**
1. **Environment variables** - Set for preview but not production
2. **Domain-specific code** - Hardcoded URLs that don't match production
3. **Caching issues** - Vercel's edge cache behaving differently
4. **Build differences** - Vercel sometimes uses different Node versions

**Solutions:**
1. Check Vercel environment variables (Settings → Environment Variables)
2. Use relative URLs or environment variable for API endpoints
3. Clear Vercel cache (Deployments → ⋯ → Redeploy → Clear cache)
4. Set explicit Node version in `package.json`:
```json
{
  "engines": {
    "node": "20.x"
  }
}
```

### Problem: CI Times Out

**Symptom:** CI runs for 10+ minutes and times out.

**Why:** Long-running tests, slow dependency install, or infinite loop.

**Solutions:**
1. **Optimize tests** - Mock slow operations, use `vi.useFakeTimers()`
2. **Better caching** - Ensure `cache: 'npm'` is set in workflow
3. **Parallel jobs** - Split tests across multiple jobs
4. **Increase timeout** - Last resort:
```yaml
- name: Run tests
  run: npm test
  timeout-minutes: 10  # Default is 5
```

**Debug tip:** Check which step is slow in GitHub Actions logs. Usually it's tests or dependency install.

## What You Should Learn From This

### 1. Automation is Worth the Setup Cost

Setting up CI/CD takes a few hours. It saves that time back in the first month by:
- Catching bugs automatically
- Eliminating manual deployment steps
- Enabling preview deployments
- Enforcing quality standards

**Key takeaway:** Invest in automation early. It compounds over time.

### 2. Fail Fast, Fail Visibly

Our CI runs fastest checks first:
1. Lint (seconds)
2. Format check (seconds)
3. Type check (seconds)
4. Tests (minutes)
5. Build (minutes)

If linting fails, we don't waste time running tests.

**Key takeaway:** Order matters. Run quick checks before slow ones.

### 3. Quality Gates Prevent Drift

Without CI, code quality slowly deteriorates:
- "I'll format this later"
- "Just one untested function"
- "This type error doesn't matter"

With CI, quality stays consistent:
- Can't merge unformatted code
- Can't merge untested code
- Can't merge type errors

**Key takeaway:** Automation enforces standards better than humans.

### 4. Preview Deployments Change Collaboration

Before preview deployments:
- "Can you pull my branch and test?"
- "Let me deploy to staging..."
- "Try localhost:3000 (oh wait, you need to run it)"

After preview deployments:
- "Here's the link, try it"

**Key takeaway:** Reduce friction for testers and reviewers. Previews are magic for non-technical stakeholders.

### 5. Configuration as Code

Our CI/CD setup is defined in code:
- `.github/workflows/ci.yml` - CI configuration
- `vercel.json` - Deployment configuration
- `package.json` - Scripts and dependencies

**Benefits:**
- Versioned (see changes over time)
- Reproducible (anyone can replicate setup)
- Documented (code explains itself)
- Reviewable (CI changes go through PR process)

**Key takeaway:** Treat infrastructure like code. Check it into git.

## Going Deeper

Want to learn more? Here are some resources:

### GitHub Actions
- [GitHub Actions Documentation](https://docs.github.com/en/actions)
- [Actions Marketplace](https://github.com/marketplace?type=actions) - Pre-built actions
- [Workflow Syntax](https://docs.github.com/en/actions/reference/workflow-syntax-for-github-actions) - Full YAML reference

### Vercel
- [Vercel Documentation](https://vercel.com/docs)
- [vercel.json Reference](https://vercel.com/docs/configuration) - All configuration options
- [Vercel CLI](https://vercel.com/docs/cli) - Deploy from command line

### CI/CD Concepts
- [Martin Fowler on Continuous Integration](https://martinfowler.com/articles/continuousIntegration.html) - Classic article
- [Continuous Delivery Book](https://continuousdelivery.com/) - Comprehensive guide
- [The DevOps Handbook](https://itrevolution.com/product/the-devops-handbook/) - Broader context

### Testing and Coverage
- [Vitest Documentation](https://vitest.dev/) - Our test framework
- [Code Coverage Best Practices](https://testing.googleblog.com/2020/08/code-coverage-best-practices.html) - Google Testing Blog

## Questions to Think About

These questions don't have single right answers, but they're worth considering:

1. **When is 90% coverage too high?** What if it's slowing down development? What if you're prototyping?

2. **When is 90% coverage too low?** What if you're building medical software? What if one bug could lose money?

3. **Should CI auto-fix formatting?** We make developers format manually. What if CI auto-formatted and committed? What are the trade-offs?

4. **When would you need multiple CI jobs?** We have one job. When would you split into parallel jobs? (Hint: testing on multiple platforms, splitting slow tests)

5. **What would you add to this CI pipeline?** Visual regression testing? Accessibility audits? Performance benchmarks? What's worth the complexity?

6. **How does this scale?** This setup works great for a solo project. What changes when you have 10 developers? 100?

## Conclusion

CI/CD is about **confidence** and **automation**. You gain confidence that code works before it reaches production. You automate the boring parts of software delivery.

BroteinBuddy's setup is intentionally simple:
- One workflow file
- Standard checks (lint, test, build)
- One hosting provider
- Minimal configuration

This simplicity is a feature, not a bug. Complex CI/CD can be fragile. Start simple, add complexity only when needed.

The key principles apply to any CI/CD setup:
- Automate repetitive tasks
- Fail fast on errors
- Make quality gates explicit
- Deploy automatically when checks pass
- Use preview environments for testing

Whether you use GitHub Actions or CircleCI, Vercel or Netlify, these principles remain the same.

Now go break something in a PR and watch CI catch it. That's the system working.
